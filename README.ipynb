{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDPC version 2\n",
    "\n",
    "A C++ rewrite of the `LDPC` package for decoding low density parity check checks. New features include:\n",
    "\n",
    "- A new C++ template class `GF2Sparse`. This is a more flexible implementation of the `mod2sparse` data structure used in the LDPCv1. This will make it much easier to expand the package.\n",
    "- Serial (and custom) schedules for the classical BP decoder.\n",
    "- An implementation of weighted union find (with Peeling and inversion solvers).\n",
    "- An implementation of belief-find (https://arxiv.org/abs/2203.04948)\n",
    "- An implementation of the Kuo and Lai memory belief propagation decoder (https://arxiv.org/abs/2104.13659)\n",
    "- Flip and P-flip decoders (https://aps.arxiv.org/abs/2212.06985)\n",
    "\n",
    "## ToDos\n",
    "\n",
    "`ldpc` is still a work in progress. Things that still need to be done:\n",
    "- More decoders could be implemented (eg. small set-flip, https://arxiv.org/abs/1810.03681).\n",
    "- ~~The LU decomposition routine needs to optimised (it is still slower than the `mod2sparse` version) (getting there...)~~\n",
    "- ~~Soft syndrome BP (https://arxiv.org/abs/2205.02341)~~\n",
    "- ~~Make a Cython wrapper for the `GF2Sparse<T>` data structure~~\n",
    "- Layered schedules (hybrid serial + parallel) (in progress). Serial version complete. Hybrid possible with OpenMp?\n",
    "- Stabiliser inactivation BP (https://arxiv.org/abs/2205.06125)\n",
    "- Generalised BP (https://arxiv.org/abs/2212.03214)\n",
    "- Functions need to be properly documented (in progress)\n",
    "- Proper test coverage is required (C++ has 100%, Python tests still need to expanded).\n",
    "- The Peeling version of union-find only works for the Toric code. A routine for matching to the boundary needs to be implemented.\n",
    "- STIM integration for circuit level noise.\n",
    "\n",
    "## Python - Installation from source\n",
    "\n",
    "The C++ source code can be found in src_cpp. Python bindings are implemented using Cython and can be found in src/ldpc. To install the Python version of the repository follows the instructions below: \n",
    "\n",
    "- Download the repo.\n",
    "- Navigate to the root.\n",
    "- Download submodules `git submodule update --init --recursive`\n",
    "- Pip install with `python>=3.8`.\n",
    "Note: installation requires a `C` compiler. Eg. `gcc` on Linux or `clang` on Windows.\n",
    "\n",
    "```\n",
    "git clone git@github.com:qec-codes/ldpc2.git\n",
    "cd ldpc2\n",
    "git submodule update --init --recursive\n",
    "pip install -Ue\n",
    "```\n",
    "\n",
    "## Installation from Test PyPi\n",
    "\n",
    "This package is currenlty hosted on TestPyPi. Installation requires Python>=3.8. To install, run the following `pip` commands.\n",
    "\n",
    "```\n",
    "pip install -U numpy scipy ldpc\n",
    "pip install -i https://test.pypi.org/simple/ ldpc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickstart\n",
    "\n",
    "I have included some *demo* codes in the `ldpc.codes` module. By default, parity check matrices are now represented as `scipy.sparse.csr_matrix` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x7 sparse matrix of type '<class 'numpy.uint8'>'\n",
       "\twith 12 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.codes import hamming_code\n",
    "\n",
    "H = hamming_code(3)\n",
    "\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 0, 0, 1, 1],\n",
       "       [1, 0, 1, 0, 1, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## To get the dense representaiton of the code, we can use the `scipy.sparse.toarray()` method\n",
    "H.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 0, 1, 1],\n",
       "       [1, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ring code\n",
    "\n",
    "from ldpc.codes import ring_code\n",
    "\n",
    "H = ring_code(4)\n",
    "H.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0],\n",
       "       [0, 1, 1, 0],\n",
       "       [0, 0, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Full rank repetition code\n",
    "\n",
    "from ldpc.codes import rep_code\n",
    "H = rep_code(4)\n",
    "H.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating code properties\n",
    "\n",
    "Code properties can be calculated with the help of GF2 linear algebra functions in the `ldpc.gf2sparse` package. This module is a Python wrapper for my *Up-Down-Left-Right* (ldpc) sparse matrix library written in C++ (this can be installed from https://github.com/qec-codes/ldpc). See examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n = 15, k = 11]\n"
     ]
    }
   ],
   "source": [
    "from ldpc.codes import hamming_code\n",
    "import ldpc.gf2sparse as gf2sparse\n",
    "\n",
    "# The rank 4 Hamming code\n",
    "H = hamming_code(4)\n",
    "\n",
    "# Physical bits\n",
    "physical_bit_count = H.shape[1]\n",
    "\n",
    "# Logical bits (by the Rank-Nullity Theorem)\n",
    "logical_bit_count = physical_bit_count - gf2sparse.rank(H)\n",
    "\n",
    "# Print code parameters\n",
    "print(f\"[n = {physical_bit_count}, k = {logical_bit_count}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also get a basis of the codewords using the kernel function\n",
    "\n",
    "codeword_basis = gf2sparse.kernel(H)\n",
    "\n",
    "codeword_basis.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, ..., 1, 0, 1],\n",
       "       [0, 1, 1, ..., 0, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1],\n",
       "       [0, 0, 0, ..., 1, 1, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, you can use the `gf2sparse.PluDecomposition` class to build your\n",
    "# own linear algebra routines. Eg. we can write a rref function\n",
    "import scipy.sparse\n",
    "import numpy as np\n",
    "import ldpc.gf2sparse as gf2sparse\n",
    "from typing import Tuple,List\n",
    "from ldpc.codes import hamming_code\n",
    "\n",
    "def rref(H: scipy.sparse.spmatrix) -> Tuple[List[int], scipy.sparse.spmatrix]:\n",
    "    \"\"\"\n",
    "    Compute the Reduced Row Echelon Form (RREF) of a given sparse matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    H : scipy.sparse.spmatrix\n",
    "        The input sparse matrix for which the RREF is to be computed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Tuple[List[int], scipy.sparse.spmatrix]\n",
    "        A tuple containing the pivot columns and the RREF of the input matrix.\n",
    "        - The first element is a list of integers representing the pivot columns.\n",
    "        - The second element is the RREF of the input matrix as a scipy.sparse.spmatrix.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialise the PLU decomposition class with the input matrix H.\n",
    "    # We set `full_reduce = False`. This means the funciton does not reduced entries above the diagonal\n",
    "    # We set `lower_triangular=False`. This means the function does not calculate the lower triangular component\n",
    "    # of the decmomposition.\n",
    "    plu_H = gf2sparse.PluDecomposition(H, full_reduce=False, lower_triangular=False)  \n",
    "    \n",
    "    # Extract the upper triangular matrix (U) from the PLU decomposition to get the RREF\n",
    "    rref_H = plu_H.U\n",
    "    \n",
    "    # Extract the pivot columns from the PLU decomposition\n",
    "    pivots_columns = plu_H.pivots\n",
    "\n",
    "    # Return a tuple containing the pivot columns and the RREF of H\n",
    "    return (pivots_columns, rref_H)\n",
    "\n",
    "pivots, H_rref = rref(H)\n",
    "\n",
    "pivots\n",
    "H_rref.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ldpc.gf2sparse` library is fast. E.g. the RREF of a $32,767$ bit Hamming code can be computed in $<1s$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[n = 32767, k = 32752]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([    0,     1,     3,     7,    15,    31,    63,   127,   255,\n",
       "          511,  1023,  2047,  4095,  8191, 16383], dtype=int32),\n",
       " <15x32767 sparse matrix of type '<class 'numpy.uint8'>'\n",
       " \twith 245760 stored elements in Compressed Sparse Row format>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ldpc.gf2sparse as gf2sparse\n",
    "from ldpc.codes import hamming_code\n",
    "\n",
    "H = hamming_code(15)\n",
    "\n",
    "print(f\"[n = {H.shape[1]}, k = {H.shape[1]-gf2sparse.rank(H)}]\")\n",
    "rref(H)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belief propagation decoding\n",
    "\n",
    "The belief propagation decoder in LDPCv2 has undergone a complete rewrite to add new functionality and make it easier to extend. There is also new syntax to bring the packge in line with modern Python standards (however, the old syntax should still work). New features include:\n",
    "\n",
    "- Serial (and layered) schedules.\n",
    "- Sparse matrix input for all decoders.\n",
    "- approx. 30% improvement in speed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.bp_decoder import BpDecoder\n",
    "from ldpc.codes import hamming_code\n",
    "import numpy as np\n",
    "\n",
    "# Rank 4 Hamming code\n",
    "H = hamming_code(4)\n",
    "\n",
    "# Call the decoder class\n",
    "decoder = BpDecoder(H, error_rate = 0.1, bp_method=\"minimum_sum\", ms_scaling_factor=0.9, schedule=\"serial\")\n",
    "\n",
    "syndrome = np.array([1,1,1,1])\n",
    "\n",
    "dec = decoder.decode(syndrome)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sparse matrix input means that the decoder can now be initialised by quickly. E.g. let's initialise a decoder for a massive $1$ million bit repetition code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ldpc.bp_decoder import BpDecoder\n",
    "from ldpc.codes import rep_code\n",
    "import numpy as np\n",
    "\n",
    "H = rep_code(1_000_000)\n",
    "decoder = BpDecoder(H, error_rate = 0.01, schedule = \"serial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BP+OSD Decoding\n",
    "\n",
    "For decoding quantum codes, it is sometimes better to use a belief propagation + ordered statistics decoder (BP+OSD). The BP+OSD implementation in LDPCv2 is more scalable than the LDPCv1. The perforance improvements can be attributed to a new row reduction routine that preserves sparsity as much as possible.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.bposd_decoder import BpOsdDecoder\n",
    "from ldpc.codes import hamming_code\n",
    "import numpy as np\n",
    "\n",
    "# Rank 10 Hamming code\n",
    "H = hamming_code(10)\n",
    "\n",
    "# Call the decoder class\n",
    "decoder = BpOsdDecoder(H, error_rate = 0.1, bp_method=\"minimum_sum\", ms_scaling_factor=0.9, schedule=\"serial\", osd_method = \"Exhaustive\", osd_order = 5)\n",
    "\n",
    "syndrome = np.array([1,1,1,1,0,0,0,0,0,0])\n",
    "\n",
    "dec = decoder.decode(syndrome)\n",
    "dec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Serial Schedules\n",
    "\n",
    "In Du Crest et al. 2023 (https://arxiv.org/abs/2308.13377v1) it is shown that using a random schedule at each iteration can improve convergence. Random scheduling can now be activated in the LDPCv2 by setting a nonzero `random_schedule_seed` when the decoder is initialised. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ldpc.bposd_decoder import BpOsdDecoder\n",
    "from ldpc.codes import hamming_code\n",
    "import numpy as np\n",
    "\n",
    "# Rank 10 Hamming code\n",
    "H = hamming_code(10)\n",
    "\n",
    "# Call the decoder class\n",
    "decoder = BpOsdDecoder(H, error_rate = 0.1, bp_method=\"minimum_sum\", ms_scaling_factor=0.9, schedule=\"serial\", osd_method = \"Exhaustive\", osd_order = 5, random_schedule_seed = 10)\n",
    "\n",
    "syndrome = np.array([1,1,1,1,0,0,0,0,0,0])\n",
    "\n",
    "dec = decoder.decode(syndrome)\n",
    "dec"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldpc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
